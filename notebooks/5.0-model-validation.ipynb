{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-11-03T05:30:05.859008600Z",
     "start_time": "2023-11-03T05:29:57.185300500Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import set_seed\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from torch import cuda\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "SEED = 42\n",
    "set_seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "device = 'cuda' if cuda.is_available() else 'cpu'\n",
    "\n",
    "model_name_fl = \"textattack/roberta-base-CoLA\"\n",
    "model_name_sta = \"SkolkovoInstitute/roberta_toxicity_classifier\"\n",
    "model_name_sim = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "\n",
    "PATH = \"../data/inheritim/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "                                           reference  \\\n0  If Alkar is flooding her with psychic waste, t...   \n1                          Now you're getting nasty.   \n2           Well, we could spare your life, for one.   \n3          Ah! Monkey, you've got to snap out of it.   \n4                   I've got orders to put her down.   \n\n                                         translation  similarity  lenght_diff  \\\n0  if Alkar floods her with her mental waste, it ...    0.785171     0.010309   \n1                        you're becoming disgusting.    0.749687     0.071429   \n2                      well, we can spare your life.    0.919051     0.268293   \n3                       monkey, you have to wake up.    0.664333     0.309524   \n4                         I have orders to kill her.    0.726639     0.181818   \n\n    ref_tox   trn_tox  avg_word_ref  avg_word_trans  \n0  0.981983  0.014195            15              16  \n1  0.999039  0.065473             4               3  \n2  0.985068  0.213313             8               6  \n3  0.994215  0.053362             9               6  \n4  0.999348  0.009402             7               6  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>reference</th>\n      <th>translation</th>\n      <th>similarity</th>\n      <th>lenght_diff</th>\n      <th>ref_tox</th>\n      <th>trn_tox</th>\n      <th>avg_word_ref</th>\n      <th>avg_word_trans</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>If Alkar is flooding her with psychic waste, t...</td>\n      <td>if Alkar floods her with her mental waste, it ...</td>\n      <td>0.785171</td>\n      <td>0.010309</td>\n      <td>0.981983</td>\n      <td>0.014195</td>\n      <td>15</td>\n      <td>16</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Now you're getting nasty.</td>\n      <td>you're becoming disgusting.</td>\n      <td>0.749687</td>\n      <td>0.071429</td>\n      <td>0.999039</td>\n      <td>0.065473</td>\n      <td>4</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Well, we could spare your life, for one.</td>\n      <td>well, we can spare your life.</td>\n      <td>0.919051</td>\n      <td>0.268293</td>\n      <td>0.985068</td>\n      <td>0.213313</td>\n      <td>8</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Ah! Monkey, you've got to snap out of it.</td>\n      <td>monkey, you have to wake up.</td>\n      <td>0.664333</td>\n      <td>0.309524</td>\n      <td>0.994215</td>\n      <td>0.053362</td>\n      <td>9</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>I've got orders to put her down.</td>\n      <td>I have orders to kill her.</td>\n      <td>0.726639</td>\n      <td>0.181818</td>\n      <td>0.999348</td>\n      <td>0.009402</td>\n      <td>7</td>\n      <td>6</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(PATH + 'filtered.csv', index_col=0)\n",
    "df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-03T05:30:07.317219500Z",
     "start_time": "2023-11-03T05:30:05.858009100Z"
    }
   },
   "id": "1423a4721bf44092"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 8)\n"
     ]
    }
   ],
   "source": [
    "df_train, df_test = train_test_split(df, test_size=0.2, random_state=SEED)\n",
    "df_test = df_test.sample(5000, random_state=SEED)\n",
    "print(df_test.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-03T05:30:07.509514Z",
     "start_time": "2023-11-03T05:30:07.314218600Z"
    }
   },
   "id": "719c227dc2f67d32"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at SkolkovoInstitute/roberta_toxicity_classifier were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at textattack/roberta-base-CoLA were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "# load tokenizer and model weights\n",
    "tokenizer_sta = AutoTokenizer.from_pretrained(model_name_sta)\n",
    "model_sta = AutoModelForSequenceClassification.from_pretrained(model_name_sta).to(device)\n",
    "\n",
    "tokenizer_sim = SentenceTransformer(model_name_sim).to(device)\n",
    "\n",
    "model_fl = AutoModelForSequenceClassification.from_pretrained(model_name_fl).to(device)\n",
    "tokenizer_fl = AutoTokenizer.from_pretrained(model_name_fl)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-03T05:30:12.930869800Z",
     "start_time": "2023-11-03T05:30:07.400514600Z"
    }
   },
   "id": "69f25fd3c1fb6ba4"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def calculate_part_sta(batch: list, tokenizer, model):\n",
    "    \"\"\"\n",
    "    calculate non-toxicity of the sentences\n",
    "    :param batch: list of sentences\n",
    "    :param tokenizer: tokenizer to encode sentences\n",
    "    :param model: model to calculate non-toxicity\n",
    "    :return: probability of each sentences\n",
    "    \"\"\"\n",
    "    text = tokenizer(batch, return_tensors='pt', padding=True, truncation=True).to(device)\n",
    "    out = model(**text)\n",
    "    return torch.softmax(out.logits, dim=-1)[:, 0].cpu()\n",
    "\n",
    "def calculate_part_score_fl(batch, tokenizer, model):\n",
    "    \"\"\"\n",
    "    calculate fluency of the sentences\n",
    "    :param batch: list of sentences\n",
    "    :param tokenizer: tokenizer to encode sentences\n",
    "    :param model: model to calculate fluency\n",
    "    :return: probability of each sentences \n",
    "    \"\"\"\n",
    "    text = tokenizer(batch, return_tensors='pt', padding=True, truncation=True).to(device)\n",
    "    out = model(**text)\n",
    "    return torch.softmax(out.logits, dim=-1)[:, 1].cpu()\n",
    "\n",
    "def calculate_sim(batch1, batch2, tokenizer):\n",
    "    \"\"\"\n",
    "    calculate similarities of the sentences\n",
    "    :param batch1: first list of sentences \n",
    "    :param batch2: second list of sentences\n",
    "    :param tokenizer: tokenizer to encode sentences\n",
    "    :return: cosine similarity of each sentences\n",
    "    \"\"\"\n",
    "    embedding_1= tokenizer.encode(batch1, convert_to_tensor=True).to(device)\n",
    "    embedding_2 = tokenizer.encode(batch2, convert_to_tensor=True).to(device)\n",
    "\n",
    "    return util.pytorch_cos_sim(embedding_1, embedding_2).diagonal(0).cpu()\n",
    "\n",
    "def calculate_joint_score(batch_reference, batch_predicted):\n",
    "    \"\"\"\n",
    "    calculate total score of the sentences based on non-toxicity, fluency, similarity\n",
    "    :param batch_reference: target list of sentences \n",
    "    :param batch_predicted: predicted list of sentences \n",
    "    :return: dict with values\n",
    "    \"\"\"\n",
    "    sta = calculate_part_sta(batch_predicted, tokenizer_sta, model_sta)\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    fl  = calculate_part_score_fl(batch_predicted, tokenizer_fl, model_fl)\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    sim = calculate_sim(batch_reference, batch_predicted, tokenizer_sim)\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    return {\n",
    "            \"non-toxic\": torch.sum(sta),\n",
    "            \"fluency\":torch.sum(fl),\n",
    "            \"similarity\": torch.sum(sim),\n",
    "            \"total\": torch.sum(sta * fl * sim)\n",
    "            }"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-03T05:30:12.943608600Z",
     "start_time": "2023-11-03T05:30:12.934868200Z"
    }
   },
   "id": "8337021655461d50"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "{'non-toxic': tensor(1.0000, grad_fn=<SumBackward0>),\n 'fluency': tensor(0.0404, grad_fn=<SumBackward0>),\n 'similarity': tensor(0.1598),\n 'total': tensor(0.0065, grad_fn=<SumBackward0>)}"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_joint_score([\"fuck fuck fuck\"], [ \"They drank the pub.\"])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-03T05:30:13.533386300Z",
     "start_time": "2023-11-03T05:30:12.938609900Z"
    }
   },
   "id": "b53fb0da2a4fc2c1"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Preparation for BERT"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "14737b20d3effe25"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "import re\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "PATH_OUT = \"../models/bert-detoxification/\"\n",
    "\n",
    "SEED = 42\n",
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-03T05:30:13.536132Z",
     "start_time": "2023-11-03T05:30:13.529176600Z"
    }
   },
   "id": "d75999d25d87dfc0"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "def clear_str(string: str) -> str:\n",
    "    \"\"\"\n",
    "    Tokenization/string cleaning for text\n",
    "    \"\"\"\n",
    "    string = re.sub('([.,!?()])', r' \\1 ', string)\n",
    "    string = re.sub(r\"\\s{2,}\", \" \", string)\n",
    "    return string.strip().lower()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-03T05:30:13.543381600Z",
     "start_time": "2023-11-03T05:30:13.534620300Z"
    }
   },
   "id": "128c9e59e0df4e8a"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "class BertClassifier(nn.Module):\n",
    "    def __init__(self, bert: BertModel, num_classes: int):\n",
    "        super().__init__()\n",
    "        self.bert = bert\n",
    "        self.classifier = nn.Linear(bert.config.hidden_size, num_classes)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask=None):\n",
    "        x = self.bert(input_ids, attention_mask=attention_mask)\n",
    "        cls_x = x[1] # sentence embedding. Pooler_output is the embedding of the [CLS] special token. It is considered as a valid representation of the complete sentence.\n",
    "        cls_x = self.classifier(cls_x)\n",
    "        # print(cls_x.shape)\n",
    "        out = self.softmax(cls_x)\n",
    "        return out\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-03T05:30:13.558105600Z",
     "start_time": "2023-11-03T05:30:13.540870500Z"
    }
   },
   "id": "d82f7044abd8fd11"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "def prediction(model: BertClassifier, out_text: list, tokenizer) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    function for doing prediciton\n",
    "    :param model: Our model\n",
    "    :param out_text: toxic text\n",
    "    :param tokenizer: tokenizer\n",
    "    :return: probabilities\n",
    "    \"\"\"\n",
    "    with torch.no_grad():\n",
    "        x = tokenizer(out_text, add_special_tokens=True, max_length=120, truncation=True, padding=True, return_tensors=\"pt\").to(device)\n",
    "        outputs = model(x[\"input_ids\"], attention_mask=x[\"attention_mask\"])\n",
    "    return outputs\n",
    "\n",
    "\n",
    "def inference(model: BertClassifier, input_text: str, tokenizer: BertTokenizer) -> str:\n",
    "    \"\"\"\n",
    "    make inference\n",
    "    :param model: Our model\n",
    "    :param input_text: toxic text\n",
    "    :param tokenizer: tokenizer\n",
    "    :return: detoxified text\n",
    "    \"\"\"\n",
    "    input_text = clear_str(input_text)\n",
    "    while True:\n",
    "        # find most toxic word\n",
    "        input_text = input_text.split()\n",
    "        out_text = [\" \".join(input_text[:i] + [\"<oov>\"] + input_text[min(i + 1, len(input_text)):]) for i in range(len(input_text))]\n",
    "        probs = prediction(model, out_text, tokenizer)\n",
    "        idx = torch.argmax(probs[:, 0])\n",
    "\n",
    "        # delete toxic word\n",
    "        input_text = re.sub(\"\\s*<oov>\\s*\", \" \", out_text[idx]).strip()\n",
    "\n",
    "        # check if sentence still toxic\n",
    "        toxicity = prediction(model, [input_text], tokenizer)\n",
    "        if torch.argmax(toxicity[0]) == 0:\n",
    "            break\n",
    "    input_text = re.sub(r'\\s([?.!,¿](?:\\s|$))', r'\\1', input_text)\n",
    "    return input_text\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-03T05:30:13.561105600Z",
     "start_time": "2023-11-03T05:30:13.547381600Z"
    }
   },
   "id": "1cc9d55578955972"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "BertClassifier(\n  (bert): BertModel(\n    (embeddings): BertEmbeddings(\n      (word_embeddings): Embedding(28996, 768, padding_idx=0)\n      (position_embeddings): Embedding(512, 768)\n      (token_type_embeddings): Embedding(2, 768)\n      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (encoder): BertEncoder(\n      (layer): ModuleList(\n        (0-11): 12 x BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n    (pooler): BertPooler(\n      (dense): Linear(in_features=768, out_features=768, bias=True)\n      (activation): Tanh()\n    )\n  )\n  (classifier): Linear(in_features=768, out_features=2, bias=True)\n  (softmax): Softmax(dim=1)\n)"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_model_name = 'bert-base-cased'\n",
    "tokenizer = BertTokenizer.from_pretrained(bert_model_name)\n",
    "bert      = BertModel.from_pretrained(bert_model_name)\n",
    "model     = BertClassifier(bert, 2).to(device)\n",
    "\n",
    "model.load_state_dict(torch.load(PATH_OUT + \"model-final.pt\"))\n",
    "model.eval()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-03T05:30:16.217072300Z",
     "start_time": "2023-11-03T05:30:13.553106700Z"
    }
   },
   "id": "45ee3cb2e3e2e924"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Calculate scores"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "357ea52a6d9740e3"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5000it [02:19, 35.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9531837767124176 0.47177488119006156 0.6414214318633079 0.2928031578540802\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "non_toxicity_bert = 0\n",
    "fluency_bert = 0\n",
    "similarity_bert = 0\n",
    "total_score_bert = 0\n",
    "\n",
    "batch_size = 32\n",
    "batch_pred = []\n",
    "batch_true = []\n",
    "\n",
    "for accum, (idx, item) in tqdm(enumerate(df_test.iterrows())):\n",
    "    pred = inference(model, item.reference, tokenizer)\n",
    "    \n",
    "    target = clear_str(item.translation)\n",
    "    target = re.sub(r'\\s([?.!,¿](?:\\s|$))', r'\\1', target)\n",
    "\n",
    "    batch_true.append(target)\n",
    "    batch_pred.append(pred)\n",
    "\n",
    "    if accum % batch_size == 0 or accum == df_test.shape[0] - 1:\n",
    "        scores = calculate_joint_score(batch_true, batch_pred)\n",
    "\n",
    "        non_toxicity_bert += scores[\"non-toxic\"].item()\n",
    "        fluency_bert += scores[\"fluency\"].item()\n",
    "        similarity_bert += scores[\"similarity\"].item()\n",
    "        total_score_bert += scores[\"total\"].item()\n",
    "        batch_true = []\n",
    "        batch_pred = []\n",
    "\n",
    "non_toxicity_bert = non_toxicity_bert / df_test.shape[0]\n",
    "fluency_bert = fluency_bert / df_test.shape[0]\n",
    "similarity_bert = similarity_bert / df_test.shape[0]\n",
    "total_score_bert = total_score_bert / df_test.shape[0]\n",
    "\n",
    "print(non_toxicity_bert, fluency_bert, similarity_bert, total_score_bert)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-03T05:32:35.914858Z",
     "start_time": "2023-11-03T05:30:16.218074200Z"
    }
   },
   "id": "8bb6ac19c0e040bb"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Preparation for encoder-decoder model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "606a890ff91d3222"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import numpy as np\n",
    "import unicodedata\n",
    "import re"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-03T05:32:35.920254Z",
     "start_time": "2023-11-03T05:32:35.913856300Z"
    }
   },
   "id": "486b90ccacd7c689"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "df_test_gru = df_test.copy()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-03T05:32:35.921254300Z",
     "start_time": "2023-11-03T05:32:35.916857800Z"
    }
   },
   "id": "c2acee16fefae99b"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "def unicode_to_ascii(s: str) -> str:\n",
    "    \"\"\"\n",
    "    Normalizes latin chars with accent to their canonical decomposition\n",
    "\n",
    "    :param s: input sentence\n",
    "    :return: normalized sentence\n",
    "    \"\"\"\n",
    "    return ''.join(c for c in unicodedata.normalize('NFD', s)\n",
    "                   if unicodedata.category(c) != 'Mn')\n",
    "\n",
    "def preprocess_sentence(w) -> str:\n",
    "    \"\"\"\n",
    "    preprocess the sentence\n",
    "    :param w: input sentence\n",
    "    :return: preprocessed sentence\n",
    "    \"\"\"\n",
    "    w = unicode_to_ascii(w.lower().strip())\n",
    "    # creating a space between a word and the punctuation following it\n",
    "    # eg: \"he is a boy.\" => \"he is a boy .\" \n",
    "    w = re.sub(r\"([?.!,¿])\", r\" \\1 \", w)\n",
    "    w = re.sub(r'[\" \"]+', \" \", w)\n",
    "    # replacing everything with space except (a-z, A-Z, \".\", \"?\", \"!\", \",\")\n",
    "    w = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", w)\n",
    "    w = w.rstrip().strip()\n",
    "    # adding a start and an end token to the sentence\n",
    "    # so that the model know when to start and stop predicting.\n",
    "    w = '<start> ' + w + ' <end>'\n",
    "    return w\n",
    "\n",
    "\n",
    "df['reference'] = df['reference'].apply(lambda w: preprocess_sentence(w))\n",
    "df['translation'] = df['translation'].apply(lambda w: preprocess_sentence(w))\n",
    "\n",
    "df_test_gru['reference'] = df_test_gru['reference'].apply(lambda w: preprocess_sentence(w))\n",
    "df_test_gru['translation'] = df_test_gru['translation'].apply(lambda w: preprocess_sentence(w))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-03T05:32:51.980537500Z",
     "start_time": "2023-11-03T05:32:35.922254Z"
    }
   },
   "id": "6cfbe1567516095a"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "# This class creates a word -> index mapping (e.g,. \"dad\" -> 5) and vice-versa \n",
    "# (e.g., 5 -> \"dad\") for each language,\n",
    "class LanguageIndex():\n",
    "    def __init__(self, lang: list):\n",
    "        \"\"\" lang are the list of phrases from each language \"\"\"\n",
    "        self.lang = lang\n",
    "        self.word2idx = {}\n",
    "        self.idx2word = {}\n",
    "        self.vocab = set()\n",
    "        self.create_index()\n",
    "\n",
    "    def create_index(self):\n",
    "        \"\"\" create word2idx, idx2word and vocab \"\"\"\n",
    "        for phrase in self.lang:\n",
    "            # update with individual tokens\n",
    "            self.vocab.update(phrase.split(' '))\n",
    "        # sort the vocab\n",
    "        self.vocab = sorted(self.vocab)\n",
    "        # add a padding token with index 0\n",
    "        self.word2idx['<pad>'] = 0\n",
    "        # word to index mapping\n",
    "        for index, word in enumerate(self.vocab):\n",
    "            self.word2idx[word] = index + 1 # +1 because of pad token\n",
    "        # index to word mapping\n",
    "        for word, index in self.word2idx.items():\n",
    "            self.idx2word[index] = word"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-03T05:32:51.994829700Z",
     "start_time": "2023-11-03T05:32:51.982538400Z"
    }
   },
   "id": "ba9ceefe2d286acc"
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "def max_length(tensor: list) -> int:\n",
    "    \"\"\"\n",
    "    calculate the max_length of input and output tensor\n",
    "    :param tensor: input tensor\n",
    "    :return: max length\n",
    "    \"\"\"\n",
    "    return max(len(t) for t in tensor)\n",
    "\n",
    "\n",
    "# index language using the class above\n",
    "inp_lang = LanguageIndex(df['reference'].values.tolist())\n",
    "targ_lang = LanguageIndex(df['translation'].values.tolist())\n",
    "\n",
    "# Vectorize the input and target languages\n",
    "input_tensor = [[inp_lang.word2idx[s] for s in reference.split(' ')]  for reference in df['reference'].values.tolist()]\n",
    "target_tensor = [[targ_lang.word2idx[s] for s in translation.split(' ')]  for translation in df['translation'].values.tolist()]\n",
    "\n",
    "max_length_inp, max_length_tar = max_length(input_tensor), max_length(target_tensor)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-03T05:32:56.457820200Z",
     "start_time": "2023-11-03T05:32:51.986829800Z"
    }
   },
   "id": "a7923a7d1420a4ae"
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, vocab_size: int, embedding_dim: int, enc_units: int, batch_sz: int):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.batch_sz = batch_sz\n",
    "        self.enc_units = enc_units\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.embedding = nn.Embedding(self.vocab_size, self.embedding_dim)\n",
    "        self.gru = nn.GRU(self.embedding_dim, self.enc_units)\n",
    "\n",
    "    def forward(self, x: torch.Tensor, device: torch.device) -> (torch.Tensor, torch.Tensor):\n",
    "        # x: batch_size, max_length \n",
    "\n",
    "        # x: batch_size, max_length, embedding_dim\n",
    "        x = self.embedding(x)\n",
    "\n",
    "        self.hidden = self.initialize_hidden_state(device)\n",
    "\n",
    "        # output: max_length, batch_size, enc_units\n",
    "        # self.hidden: 1, batch_size, enc_units\n",
    "        output, self.hidden = self.gru(x, self.hidden) # gru returns hidden state of all timesteps as well as hidden state at last timestep\n",
    "\n",
    "        return output, self.hidden\n",
    "\n",
    "    def initialize_hidden_state(self, device: torch.device) -> torch.Tensor:\n",
    "        return torch.zeros((1, self.batch_sz, self.enc_units)).to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-03T05:32:56.471988900Z",
     "start_time": "2023-11-03T05:32:56.459820Z"
    }
   },
   "id": "1055803bc944c218"
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, vocab_size: int, embedding_dim: int, dec_units: int, enc_units: int, batch_sz: int):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.batch_sz = batch_sz\n",
    "        self.dec_units = dec_units\n",
    "        self.enc_units = enc_units\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.embedding = nn.Embedding(self.vocab_size, self.embedding_dim)\n",
    "        self.gru = nn.GRU(self.embedding_dim + self.enc_units,\n",
    "                          self.dec_units,\n",
    "                          batch_first=True)\n",
    "        self.fc = nn.Linear(self.enc_units, self.vocab_size)\n",
    "\n",
    "        # used for attention\n",
    "        self.W1 = nn.Linear(self.enc_units, self.dec_units)\n",
    "        self.W2 = nn.Linear(self.enc_units, self.dec_units)\n",
    "        self.V = nn.Linear(self.enc_units, 1)\n",
    "\n",
    "    def forward(self, x: torch.Tensor, hidden: torch.Tensor, enc_output: torch.Tensor) -> (torch.Tensor, torch.Tensor, torch.Tensor):\n",
    "        # enc_output converted == (batch_size, max_length, hidden_size)\n",
    "        enc_output = enc_output.permute(1,0,2)\n",
    "\n",
    "        # hidden shape == (batch_size, hidden size) we convert it to (batch_size, 1, hidden size)\n",
    "        hidden_with_time_axis = hidden.permute(1, 0, 2)\n",
    "\n",
    "        # score: (batch_size, max_length, hidden_size) # Bahdanaus's\n",
    "        # It doesn't matter which FC we pick for each of the inputs\n",
    "        score = self.V(torch.tanh(self.W2(enc_output) + self.W1(hidden_with_time_axis)))\n",
    "\n",
    "        #attention_weights shape == (batch_size, max_length, 1)\n",
    "        attention_weights = nn.Softmax(dim=1)(score)\n",
    "\n",
    "        # context_vector shape after sum == (batch_size, hidden_size)\n",
    "        context_vector = torch.sum(attention_weights * enc_output, dim=1)\n",
    "\n",
    "        # pass the context vector into embedding layer\n",
    "        # x shape after passing through embedding == (batch_size, 1, embedding_dim)\n",
    "        x = self.embedding(x)\n",
    "\n",
    "        # concatenate the context vector and x\n",
    "        # x shape after concatenation == (batch_size, 1, embedding_dim + hidden_size)\n",
    "        x = torch.cat((context_vector.unsqueeze(1), x), -1)\n",
    "\n",
    "        # passing the concatenated vector to the GRU\n",
    "        # output: (batch_size, 1, hidden_size)\n",
    "        output, state = self.gru(x)\n",
    "\n",
    "        # output shape == (batch_size * 1, hidden_size)\n",
    "        output =  output.view(-1, output.size(2))\n",
    "\n",
    "        # output shape == (batch_size * 1, vocab)\n",
    "        x = self.fc(output)\n",
    "        return x, state, attention_weights\n",
    "\n",
    "    def initialize_hidden_state(self) -> torch.Tensor:\n",
    "        return torch.zeros((1, self.batch_sz, self.dec_units))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-03T05:32:56.471988900Z",
     "start_time": "2023-11-03T05:32:56.465642300Z"
    }
   },
   "id": "e3464665a45cddfc"
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "data": {
      "text/plain": "Decoder(\n  (embedding): Embedding(61679, 256)\n  (gru): GRU(768, 512, batch_first=True)\n  (fc): Linear(in_features=512, out_features=61679, bias=True)\n  (W1): Linear(in_features=512, out_features=512, bias=True)\n  (W2): Linear(in_features=512, out_features=512, bias=True)\n  (V): Linear(in_features=512, out_features=1, bias=True)\n)"
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PATH_OUT = \"../models/gru-detoxification/\"\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "embedding_dim = 256\n",
    "units = 512\n",
    "vocab_inp_size = len(inp_lang.word2idx)\n",
    "vocab_tar_size = len(targ_lang.word2idx)\n",
    "\n",
    "encoder = Encoder(vocab_inp_size, embedding_dim, units, BATCH_SIZE)\n",
    "decoder = Decoder(vocab_tar_size, embedding_dim, units, units, BATCH_SIZE)\n",
    "\n",
    "encoder.load_state_dict(torch.load(PATH_OUT + \"encoder-final.pt\"))\n",
    "decoder.load_state_dict(torch.load(PATH_OUT + \"decoder-final.pt\"))\n",
    "\n",
    "encoder.to(device)\n",
    "decoder.to(device)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-03T05:35:10.130717400Z",
     "start_time": "2023-11-03T05:35:09.410583Z"
    }
   },
   "id": "b6c9b797eb394543"
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "def pad_sequences(x: list, max_len: int) -> list:\n",
    "    \"\"\"\n",
    "    add padding\n",
    "    :param x: token's sentence\n",
    "    :param max_len: max length of words from column\n",
    "    :return: token's sentence with padding\n",
    "    \"\"\"\n",
    "    padded = np.zeros((max_len), dtype=np.int64)\n",
    "    if len(x) > max_len: padded[:] = x[:max_len]\n",
    "    else: padded[:len(x)] = x\n",
    "    return padded"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-03T05:35:23.533559600Z",
     "start_time": "2023-11-03T05:35:23.516558400Z"
    }
   },
   "id": "df84f201ed3317b4"
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "def inference(encoder: Encoder, decoder: Decoder, sentence: str, special_tokens: bool=True) -> list:\n",
    "    \"\"\"\n",
    "    get inference of the encoder-decoder model\n",
    "    :param encoder: our encoder\n",
    "    :param decoder: our decoder\n",
    "    :param sentence: toxic sentence\n",
    "    :param special_tokens: print special tokens or not\n",
    "    :return: translated text\n",
    "    \"\"\"\n",
    "    encoder.eval()\n",
    "    decoder.eval()\n",
    "\n",
    "    sentence = torch.unsqueeze(sentence, dim=1)\n",
    "    with torch.no_grad():\n",
    "        enc_output, enc_hidden = encoder(sentence.to(device), device)\n",
    "        dec_hidden = enc_hidden\n",
    "        dec_input = torch.tensor([[targ_lang.word2idx['<start>']]] * 1)\n",
    "\n",
    "        out_sentence = []\n",
    "        for t in range(1, sentence.size(0)):\n",
    "            predictions, dec_hidden, _ = decoder(dec_input.to(device),\n",
    "                                                 dec_hidden.to(device),\n",
    "                                                 enc_output.to(device))\n",
    "            dec_input = predictions.argmax(dim=1).unsqueeze(1)\n",
    "            out_word = targ_lang.idx2word[predictions.squeeze().argmax().item()]\n",
    "            if special_tokens:\n",
    "                out_sentence.append(out_word)\n",
    "            else:\n",
    "                if out_word != \"<pad>\" and out_word != \"<end>\":\n",
    "                    out_sentence.append(out_word)\n",
    "\n",
    "    out_sentence = \" \".join(out_sentence)\n",
    "    out_sentence = re.sub(r'\\s([?.!,¿](?:\\s|$))', r'\\1', out_sentence)\n",
    "    return out_sentence\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-03T05:35:23.725619500Z",
     "start_time": "2023-11-03T05:35:23.702617500Z"
    }
   },
   "id": "168182b0001b41b7"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Calculate scores"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f6bd2b243e195b60"
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5000it [23:09,  3.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6517880827307702 0.5338920620784163 0.549631848704815 0.19717650542557238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "encoder.batch_sz = 1\n",
    "encoder.initialize_hidden_state(device)\n",
    "decoder.batch_sz = 1\n",
    "decoder.initialize_hidden_state()\n",
    "\n",
    "batch_size = 8\n",
    "batch_pred = []\n",
    "batch_true = []\n",
    "\n",
    "non_toxicity_gru = 0\n",
    "fluency_gru = 0\n",
    "similarity_gru = 0\n",
    "total_score_gru = 0\n",
    "\n",
    "for accum, (idx, item) in tqdm(enumerate(df_test_gru.iterrows())):    \n",
    "    test_sentence = item.reference\n",
    "    test_sentence = [inp_lang.word2idx[s] for s in test_sentence.split(' ')]\n",
    "    test_sentence = pad_sequences(test_sentence, max_length_inp)\n",
    "    \n",
    "    pred = inference(encoder, decoder, torch.tensor(test_sentence).to(device), special_tokens=False)\n",
    "\n",
    "    target = \" \".join(item.translation.split()[1:-1])\n",
    "    target = re.sub(r'\\s([?.!,¿](?:\\s|$))', r'\\1', target)\n",
    "\n",
    "\n",
    "    batch_true.append(target)\n",
    "    batch_pred.append(pred)\n",
    "    if accum % batch_size == 0 or accum == df_test_gru.shape[0] - 1:\n",
    "        scores = calculate_joint_score(batch_true, batch_pred)\n",
    "\n",
    "        non_toxicity_gru += scores[\"non-toxic\"].item()\n",
    "        fluency_gru += scores[\"fluency\"].item()\n",
    "        similarity_gru += scores[\"similarity\"].item()\n",
    "        total_score_gru += scores[\"total\"].item()\n",
    "\n",
    "        batch_true = []\n",
    "        batch_pred = []\n",
    "\n",
    "\n",
    "non_toxicity_gru = non_toxicity_gru / df_test_gru.shape[0]\n",
    "fluency_gru = fluency_gru / df_test_gru.shape[0]\n",
    "similarity_gru = similarity_gru / df_test_gru.shape[0]\n",
    "total_score_gru = total_score_gru / df_test_gru.shape[0]\n",
    "\n",
    "print(non_toxicity_gru, fluency_gru, similarity_gru, total_score_gru)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-03T05:58:41.795673600Z",
     "start_time": "2023-11-03T05:35:32.591873100Z"
    }
   },
   "id": "66fe6f66b1fb690"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Preparation for T5"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "353088ff9680dd6d"
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "\n",
    "SAVE_PATH = \"../models/t5-detoxification/checkpoint-final/\"\n",
    "model_checkpoint = \"t5-small\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-03T05:58:41.812673900Z",
     "start_time": "2023-11-03T05:58:41.793317400Z"
    }
   },
   "id": "b4f41b7dddf36e0d"
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [],
   "source": [
    "model = AutoModelForSeq2SeqLM.from_pretrained(SAVE_PATH).to(device)\n",
    "model.eval()\n",
    "model.config.use_cache = False\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-03T05:58:43.798696800Z",
     "start_time": "2023-11-03T05:58:41.796674400Z"
    }
   },
   "id": "7828417c7a3a5835"
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [],
   "source": [
    "def inference(model, inference_request, tokenizer=tokenizer):\n",
    "    \"\"\"\n",
    "    get inference of the t5 model\n",
    "    :param model: fine-tuned model \n",
    "    :param inference_request: toxic text\n",
    "    :param tokenizer: t5 tokenizer\n",
    "    :return: translated text\n",
    "    \"\"\"\n",
    "    inputs = tokenizer(inference_request, return_tensors=\"pt\").to(device)\n",
    "    inputs = {k: v for k, v in inputs.items()}\n",
    "\n",
    "    outputs = model.generate(**inputs, num_beams=1, do_sample=False)\n",
    "    for ex in outputs:\n",
    "        return tokenizer.decode(ex, skip_special_tokens=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-03T05:58:43.803428600Z",
     "start_time": "2023-11-03T05:58:43.799696700Z"
    }
   },
   "id": "2fa44852aa56ce08"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Calculate scores"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "150cbafc56d08fe3"
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5000it [05:55, 14.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6123539594650269 0.7395521600604057 0.6748421402215957 0.3157254221439362\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "\n",
    "batch_size = 32\n",
    "batch_pred = []\n",
    "batch_true = []\n",
    "\n",
    "non_toxicity_t5 = 0\n",
    "fluency_t5 = 0\n",
    "similarity_t5 = 0\n",
    "total_score_t5 = 0\n",
    "\n",
    "\n",
    "for accum, (idx, item) in tqdm(enumerate(df_test.iterrows())):\n",
    "    test_sentence = item.reference\n",
    "    pred = inference(model, item.reference.lower().strip(), tokenizer)\n",
    "    target = item.translation.lower().strip()\n",
    "\n",
    "    batch_true.append(target)\n",
    "    batch_pred.append(pred)\n",
    "    if accum % batch_size == 0 or accum == df_test.shape[0] - 1:\n",
    "        scores = calculate_joint_score(batch_true, batch_pred)\n",
    "\n",
    "        non_toxicity_t5 += scores[\"non-toxic\"].item()\n",
    "        fluency_t5 += scores[\"fluency\"].item()\n",
    "        similarity_t5 += scores[\"similarity\"].item()\n",
    "        total_score_t5 += scores[\"total\"].item()\n",
    "\n",
    "        batch_true = []\n",
    "        batch_pred = []\n",
    "\n",
    "\n",
    "non_toxicity_t5 = non_toxicity_t5 / df_test.shape[0]\n",
    "fluency_t5 = fluency_t5 / df_test.shape[0]\n",
    "similarity_t5 = similarity_t5 / df_test.shape[0]\n",
    "total_score_t5 = total_score_t5 / df_test.shape[0]\n",
    "\n",
    "print(non_toxicity_t5, fluency_t5, similarity_t5, total_score_t5)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-03T06:04:39.257881100Z",
     "start_time": "2023-11-03T05:58:43.805428400Z"
    }
   },
   "id": "6e8cdb773f77b653"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Results"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d2825283f7398cf3"
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "data": {
      "text/plain": "                      STA        FL       SIM     Total\nBERT Deletion    0.953184  0.471775  0.641421  0.292803\nEncoder-Decoder  0.651788  0.533892  0.549632  0.197177\nT5-small         0.612354  0.739552  0.674842  0.315725",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>STA</th>\n      <th>FL</th>\n      <th>SIM</th>\n      <th>Total</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>BERT Deletion</th>\n      <td>0.953184</td>\n      <td>0.471775</td>\n      <td>0.641421</td>\n      <td>0.292803</td>\n    </tr>\n    <tr>\n      <th>Encoder-Decoder</th>\n      <td>0.651788</td>\n      <td>0.533892</td>\n      <td>0.549632</td>\n      <td>0.197177</td>\n    </tr>\n    <tr>\n      <th>T5-small</th>\n      <td>0.612354</td>\n      <td>0.739552</td>\n      <td>0.674842</td>\n      <td>0.315725</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = {\n",
    "        \"BERT Deletion\": [non_toxicity_bert, fluency_bert, similarity_bert, total_score_bert],\n",
    "        \"Encoder-Decoder\": [non_toxicity_gru, fluency_gru, similarity_gru, total_score_gru],\n",
    "        \"T5-small\": [non_toxicity_t5, fluency_t5, similarity_t5, total_score_t5]\n",
    "        }\n",
    "columns = [\"STA\", \"FL\", \"SIM\", \"Total\"]\n",
    "\n",
    "results = pd.DataFrame.from_dict(data, orient='index', columns=columns)\n",
    "results"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-03T06:04:39.277019100Z",
     "start_time": "2023-11-03T06:04:39.256881200Z"
    }
   },
   "id": "c08894dcec9e9c21"
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [],
   "source": [
    "results.to_csv(\"../reports/\" + \"result.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-03T06:05:44.972329Z",
     "start_time": "2023-11-03T06:05:44.853859300Z"
    }
   },
   "id": "7617fa8d77fbb115"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "8a13b279d93ebedc"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
