{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-11-05T10:45:23.644242700Z",
     "start_time": "2023-11-05T10:45:21.732773200Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "from torch import cuda\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "device = 'cuda' if cuda.is_available() else 'cpu'\n",
    "SAVE_PATH = \"../models/t5-detoxification/checkpoint-final/\"\n",
    "model_checkpoint = \"t5-small\""
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Download model from checkpoint"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d8546282b90f64d7"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "model = AutoModelForSeq2SeqLM.from_pretrained(SAVE_PATH).to(device)\n",
    "model.eval()\n",
    "model.config.use_cache = False\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-05T10:45:25.741674700Z",
     "start_time": "2023-11-05T10:45:23.646246300Z"
    }
   },
   "id": "449b336853ee0731"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Inference"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "db517d43e239c8b8"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def inference(model: AutoModelForSeq2SeqLM, inference_request: str, tokenizer: AutoTokenizer) -> str:\n",
    "    \"\"\"\n",
    "    get inference of the t5 model\n",
    "    :param model: fine-tuned model \n",
    "    :param inference_request: toxic text\n",
    "    :param tokenizer: t5 tokenizer\n",
    "    :return: translated text\n",
    "    \"\"\"\n",
    "    inputs = tokenizer(inference_request, return_tensors=\"pt\").to(device)\n",
    "    inputs = {k: v for k, v in inputs.items()}\n",
    "\n",
    "    outputs = model.generate(**inputs, num_beams=1, do_sample=False)\n",
    "    for ex in outputs:\n",
    "        return tokenizer.decode(ex, skip_special_tokens=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-05T10:45:25.745676Z",
     "start_time": "2023-11-05T10:45:25.744158600Z"
    }
   },
   "id": "d91c833d2e72b7dd"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "\"I'm cool.\""
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inference(model, \"I am fucking cool.\", tokenizer)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-05T10:45:26.244953600Z",
     "start_time": "2023-11-05T10:45:25.746676900Z"
    }
   },
   "id": "c06ebb3be2c0ba9e"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-05T10:45:26.248465700Z",
     "start_time": "2023-11-05T10:45:26.244953600Z"
    }
   },
   "id": "dfbccbc0e3920fb0"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
