{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-11-03T20:05:27.117006400Z",
     "start_time": "2023-11-03T20:05:25.215990800Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "from torch import cuda\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "device = 'cuda' if cuda.is_available() else 'cpu'\n",
    "SAVE_PATH = \"../models/t5-detoxification/checkpoint-final/\"\n",
    "model_checkpoint = \"t5-small\""
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Download model from checkpoint"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d8546282b90f64d7"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "model = AutoModelForSeq2SeqLM.from_pretrained(SAVE_PATH).to(device)\n",
    "model.eval()\n",
    "model.config.use_cache = False\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-03T20:05:29.651891800Z",
     "start_time": "2023-11-03T20:05:27.117006400Z"
    }
   },
   "id": "449b336853ee0731"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Inference"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "db517d43e239c8b8"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def inference(model: AutoModelForSeq2SeqLM, inference_request: str, tokenizer: AutoTokenizer) -> str:\n",
    "    \"\"\"\n",
    "    get inference of the t5 model\n",
    "    :param model: fine-tuned model \n",
    "    :param inference_request: toxic text\n",
    "    :param tokenizer: t5 tokenizer\n",
    "    :return: translated text\n",
    "    \"\"\"\n",
    "    inputs = tokenizer(inference_request, return_tensors=\"pt\").to(device)\n",
    "    inputs = {k: v for k, v in inputs.items()}\n",
    "\n",
    "    outputs = model.generate(**inputs, num_beams=1, do_sample=False)\n",
    "    for ex in outputs:\n",
    "        return tokenizer.decode(ex, skip_special_tokens=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-03T20:05:29.657089200Z",
     "start_time": "2023-11-03T20:05:29.654890300Z"
    }
   },
   "id": "d91c833d2e72b7dd"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "\"I'm so cool!\""
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inference(model, \"I am so fucking cool!\", tokenizer)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-03T20:05:30.180091200Z",
     "start_time": "2023-11-03T20:05:29.658091200Z"
    }
   },
   "id": "c06ebb3be2c0ba9e"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-03T20:05:30.182816700Z",
     "start_time": "2023-11-03T20:05:30.181090500Z"
    }
   },
   "id": "dfbccbc0e3920fb0"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
