{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-11-05T10:44:03.072532100Z",
     "start_time": "2023-11-05T10:44:00.596785100Z"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "device = torch.device('cpu')\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda:0')\n",
    "\n",
    "PATH_OUT = \"../models/bert-detoxification/\"\n",
    "\n",
    "SEED = 42\n",
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Preparation for Inference "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "94f32e7ff8e4c4f5"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "def clear_str(string: str) -> str:\n",
    "    \"\"\"\n",
    "    Tokenization/string cleaning for text\n",
    "    \"\"\"\n",
    "    # creating a space between a word and the punctuation following it\n",
    "    # eg: \"he is a boy.\" => \"he is a boy .\" \n",
    "    string = re.sub(r\"([?.!,¿])\", r\" \\1 \", string)\n",
    "    string = re.sub(r'[\" \"]+', \" \", string)\n",
    "    # replacing everything with space except (a-z, A-Z, \".\", \"?\", \"!\", \",\")\n",
    "    string = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", string)\n",
    "    return string.strip().lower()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-05T10:44:03.079526900Z",
     "start_time": "2023-11-05T10:44:03.075014200Z"
    }
   },
   "id": "143cbee42ea43573"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "class BertClassifier(nn.Module):\n",
    "    def __init__(self, bert: BertModel, num_classes: int):\n",
    "        super().__init__()\n",
    "        self.bert = bert\n",
    "        self.classifier = nn.Linear(bert.config.hidden_size, num_classes)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask=None):\n",
    "        x = self.bert(input_ids, attention_mask=attention_mask)\n",
    "        cls_x = x[1] # sentence embedding. Pooler_output is the embedding of the [CLS] special token. It is considered as a valid representation of the complete sentence.\n",
    "        cls_x = self.classifier(cls_x)\n",
    "        # print(cls_x.shape)\n",
    "        out = self.softmax(cls_x)\n",
    "        return out\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-05T10:44:03.085818300Z",
     "start_time": "2023-11-05T10:44:03.080305300Z"
    }
   },
   "id": "bf40679e8eafc3f0"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def prediction(model: BertClassifier, out_text: list, tokenizer) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    function for doing prediciton\n",
    "    :param model: Our model\n",
    "    :param out_text: toxic text\n",
    "    :param tokenizer: tokenizer\n",
    "    :return: probabilities\n",
    "    \"\"\"\n",
    "    with torch.no_grad():\n",
    "        x = tokenizer(out_text, add_special_tokens=True, max_length=120, truncation=True, padding=True, return_tensors=\"pt\").to(device)\n",
    "        outputs = model(x[\"input_ids\"], attention_mask=x[\"attention_mask\"])\n",
    "    return outputs\n",
    "\n",
    "\n",
    "def inference(model: BertClassifier, input_text: str, tokenizer: BertTokenizer) -> str:\n",
    "    \"\"\"\n",
    "    make inference\n",
    "    :param model: Our model\n",
    "    :param input_text: toxic text\n",
    "    :param tokenizer: tokenizer\n",
    "    :return: detoxified text\n",
    "    \"\"\"\n",
    "    input_text = clear_str(input_text)\n",
    "    while True:\n",
    "        # find most toxic word\n",
    "        input_text = input_text.split()\n",
    "        out_text = [\" \".join(input_text[:i] + [\"<oov>\"] + input_text[min(i + 1, len(input_text)):]) for i in range(len(input_text))]\n",
    "        probs = prediction(model, out_text, tokenizer)\n",
    "        idx = torch.argmax(probs[:, 0])\n",
    "        \n",
    "        # delete toxic word\n",
    "        input_text = re.sub(\"\\s*<oov>\\s*\", \" \", out_text[idx]).strip()\n",
    "        \n",
    "        # check if sentence still toxic\n",
    "        toxicity = prediction(model, [input_text], tokenizer)\n",
    "        if torch.argmax(toxicity[0]) == 0:\n",
    "            break\n",
    "    input_text = re.sub(r'\\s([?.!,¿](?:\\s|$))', r'\\1', input_text)\n",
    "    return input_text\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-05T10:44:03.090904600Z",
     "start_time": "2023-11-05T10:44:03.085818300Z"
    }
   },
   "id": "c3a4a60dd5cccc59"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "BertClassifier(\n  (bert): BertModel(\n    (embeddings): BertEmbeddings(\n      (word_embeddings): Embedding(28996, 768, padding_idx=0)\n      (position_embeddings): Embedding(512, 768)\n      (token_type_embeddings): Embedding(2, 768)\n      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (encoder): BertEncoder(\n      (layer): ModuleList(\n        (0-11): 12 x BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n    (pooler): BertPooler(\n      (dense): Linear(in_features=768, out_features=768, bias=True)\n      (activation): Tanh()\n    )\n  )\n  (classifier): Linear(in_features=768, out_features=2, bias=True)\n  (softmax): Softmax(dim=1)\n)"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_model_name = 'bert-base-cased'\n",
    "tokenizer = BertTokenizer.from_pretrained(bert_model_name)\n",
    "bert      = BertModel.from_pretrained(bert_model_name)\n",
    "model     = BertClassifier(bert, 2).to(device)\n",
    "\n",
    "model.load_state_dict(torch.load(PATH_OUT + \"model-final.pt\"))\n",
    "model.eval()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-05T10:44:07.866370100Z",
     "start_time": "2023-11-05T10:44:03.090904600Z"
    }
   },
   "id": "ba1ff573ab73fd39"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Inference"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b261c62bb6e96ef5"
  },
  {
   "cell_type": "markdown",
   "source": [
    "In this approach we use BertClassifier to detect is this sentence toxic or not. From initial sentence I make several variants of sentence replacing each word to <oov> to see what word affect mostly, then delete it. I do it till classifier detect sentence as non-toxic."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f14d15f4ec83be3a"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "'i am cool.'"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inference(model, \"i am fucking cool.\", tokenizer)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-05T10:44:08.261853700Z",
     "start_time": "2023-11-05T10:44:07.867366300Z"
    }
   },
   "id": "1bc23718ed318c92"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-05T10:44:08.261853700Z",
     "start_time": "2023-11-05T10:44:08.258366800Z"
    }
   },
   "id": "faa8924f1b53e37c"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
